{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSectionError",
     "evalue": "No section: 'AWS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSectionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-73c1764fc907>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dwh.cfg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mKEY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AWS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'KEY'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mSECRET\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AWS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SECRET'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\configparser.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, section, option, raw, vars, fallback)\u001b[0m\n\u001b[0;32m    779\u001b[0m         \"\"\"\n\u001b[0;32m    780\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m             \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unify_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mNoSectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfallback\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0m_UNSET\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\configparser.py\u001b[0m in \u001b[0;36m_unify_values\u001b[1;34m(self, section, vars)\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msection\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_section\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mNoSectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msection\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m         \u001b[1;31m# Update with the entry specific variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m         \u001b[0mvardict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSectionError\u001b[0m: No section: 'AWS'"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')\n",
    "\n",
    "KEY = config.get('AWS', 'KEY')\n",
    "SECRET = config.get('AWS', 'SECRET')\n",
    "\n",
    "ARN = config.get('IAM_ROLE', 'ARN')\n",
    "LOG_DATA = config.get('S3', 'LOG_DATA')\n",
    "LOG_JSONPATH = config.get('S3', 'LOG_JSONPATH')\n",
    "SONG_DATA = config.get('S3', 'SONG_DATA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the data in s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_json_path.json\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                    region_name = 'us-west-2',\n",
    "                    aws_access_key_id = KEY,\n",
    "                    aws_secret_access_key = SECRET\n",
    "                   )\n",
    "\n",
    "a = s3.Bucket(\"udacity-dend\")\n",
    "for i in a.objects.filter(Prefix=\"log_json\"):\n",
    "    print(i.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')\n",
    "\n",
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP TABLES\n",
    "staging_events_table_drop = \"DROP TABLE IF EXISTS staging_events\"\n",
    "staging_songs_table_drop = \"DROP TABLE IF EXISTS staging_songs\"\n",
    "songplay_table_drop = \"DROP TABLE IF EXISTS songplays\"\n",
    "user_table_drop = \"DROP TABLE IF EXISTS users\"\n",
    "song_table_drop = \"DROP TABLE IF EXISTS songs\"\n",
    "artist_table_drop = \"DROP TABLE IF EXISTS artists\"\n",
    "time_table_drop = \"DROP TABLE IF EXISTS time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_queries = [staging_events_table_drop, staging_songs_table_drop, songplay_table_drop, user_table_drop, song_table_drop, artist_table_drop, time_table_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in create_table_queries:\n",
    "    cur.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TABLES\n",
    "\n",
    "staging_events_table_create= (\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS stage_events\n",
    "    (\n",
    "        artist VARCHAR,\n",
    "        auth VARCHAR,\n",
    "        firstName VARCHAR,\n",
    "        gender VARCHAR,\n",
    "        itemInSession INT,\n",
    "        lastName VARCHAR,\n",
    "        length NUMERIC,\n",
    "        level VARCHAR,\n",
    "        location VARCHAR,\n",
    "        method VARCHAR,\n",
    "        page VARCHAR,\n",
    "        registration BIGINT,\n",
    "        sessionId INT,\n",
    "        song VARCHAR,\n",
    "        status INT,\n",
    "        ts BIGINT,\n",
    "        userAgent VARCHAR,\n",
    "        userId INT\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "staging_songs_table_create = (\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS staging_songs\n",
    "    (\n",
    "        num_songs INT,\n",
    "        artist_id VARCHAR,\n",
    "        artist_latitude NUMERIC,\n",
    "        artist_longitude NUMERIC, \n",
    "        artist_location VARCHAR,\n",
    "        artist_name VARCHAR,\n",
    "        song_id VARCHAR, \n",
    "        title VARCHAR, \n",
    "        duration NUMERIC,\n",
    "        year INT\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "songplay_table_create = (\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS songplays\n",
    "    (\n",
    "        songplay_id INT IDENTITY(0,1) PRIMARY KEY, \n",
    "        start_time TIMESTAMP NOT NULL, \n",
    "        user_id INT NOT NULL, \n",
    "        level VARCHAR, \n",
    "        song_id VARCHAR, \n",
    "        artist_id VARCHAR, \n",
    "        session_id INT, \n",
    "        location VARCHAR, \n",
    "        user_agent VARCHAR,\n",
    "        UNIQUE (start_time, user_id, song_id, artist_id)\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "user_table_create = (\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS users\n",
    "    (\n",
    "        user_id INT PRIMARY KEY, \n",
    "        first_name VARCHAR NOT NULL, \n",
    "        last_name VARCHAR NOT NULL, \n",
    "        gender VARCHAR, \n",
    "        level VARCHAR NOT NULL\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "song_table_create = (\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS songs\n",
    "    (\n",
    "        song_id VARCHAR PRIMARY KEY, \n",
    "        title VARCHAR NOT NULL, \n",
    "        artist_id VARCHAR, \n",
    "        year INT, \n",
    "        duration NUMERIC\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "artist_table_create = (\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS artists\n",
    "    (\n",
    "        artist_id VARCHAR PRIMARY KEY,\n",
    "        name VARCHAR NOT NULL,\n",
    "        location VARCHAR,\n",
    "        latitude NUMERIC,\n",
    "        longitude NUMERIC\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "time_table_create = (\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS time\n",
    "    (\n",
    "        start_time TIMESTAMP PRIMARY KEY,\n",
    "        hour INT,\n",
    "        day INT,\n",
    "        week INT,\n",
    "        month INT,\n",
    "        year INT,\n",
    "        weekday INT\n",
    "    );\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_queries = [staging_events_table_create, staging_songs_table_create, songplay_table_create, user_table_create, song_table_create, artist_table_create, time_table_create]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in create_table_queries:\n",
    "    cur.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGING TABLES\n",
    "staging_events_copy = (\"\"\"\n",
    "    COPY stage_events FROM {}\n",
    "    credentials 'aws_iam_role={}'\n",
    "    region 'us-west-2'\n",
    "    format as json {};\n",
    "\"\"\").format(LOG_DATA, ARN, LOG_JSONPATH)\n",
    "\n",
    "staging_songs_copy = (\"\"\"\n",
    "    COPY staging_songs FROM {}\n",
    "    credentials 'aws_iam_role={}'\n",
    "    region 'us-west-2'\n",
    "    json 'auto'\n",
    "\"\"\").format(SONG_DATA, ARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_table_queries = [staging_events_copy, staging_songs_copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in copy_table_queries:\n",
    "    cur.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "songplay_table_insert = (\"\"\"\n",
    "    INSERT INTO songplays (start_time, user_id, level, song_id, artist_id, session_id, location, user_agent)\n",
    "    SELECT \n",
    "        DISTINCT (TIMESTAMP 'epoch' + se.ts/1000 * INTERVAL '1 second') AS start_time, \n",
    "        se.userId       AS user_id,\n",
    "        se.level        AS level,\n",
    "        ss.num_songs    AS song_id,\n",
    "        ss.artist_id    AS artist_id,\n",
    "        se.sessionId    AS session_id, \n",
    "        se.location     AS location, \n",
    "        se.userAgent    AS user_agent\n",
    "    FROM stage_events se\n",
    "    JOIN staging_songs ss ON se.song = ss.title AND se.artist = ss.artist_name AND se.length = ss.duration\n",
    "    WHERE se.page = 'NextSong' ; \n",
    "\"\"\")\n",
    "\n",
    "user_table_insert = (\"\"\"\n",
    "    INSERT INTO users (user_id, first_name, last_name, gender, level)\n",
    "    SELECT\n",
    "        DISTINCT se.userId      AS user_id,\n",
    "        se.firstName            AS first_name, \n",
    "        se.lastName             AS last_name,\n",
    "        se.gender               AS gender,\n",
    "        se.level                AS level\n",
    "    FROM stage_events se\n",
    "    WHERE se.page = 'NextSong';\n",
    "\"\"\")\n",
    "\n",
    "song_table_insert = (\"\"\"\n",
    "    INSERT INTO songs (song_id, title, artist_id, year, duration)\n",
    "    SELECT\n",
    "        DISTINCT ss.num_songs        AS song_id,\n",
    "        ss.title                     AS title,    \n",
    "        ss.artist_id                 AS artist_id,\n",
    "        ss.year                      AS year,\n",
    "        ss.duration                  AS duration\n",
    "    FROM staging_songs ss\n",
    "    WHERE song_id NOT IN (SELECT DISTINCT song_id FROM songs);\n",
    "\"\"\")\n",
    "\n",
    "artist_table_insert = (\"\"\"\n",
    "    INSERT INTO artists (artist_id, name, location, latitude, longitude)\n",
    "    SELECT\n",
    "        DISTINCT ss.artist_id   AS artist_id,\n",
    "        ss.artist_name          AS name,\n",
    "        ss.artist_location      AS location,    \n",
    "        ss.artist_latitude      AS latitude,\n",
    "        ss.artist_longitude     AS longitude\n",
    "    FROM staging_songs ss\n",
    "    WHERE artist_id NOT IN (SELECT DISTINCT artist_id FROM artists);\n",
    "\"\"\")\n",
    "\n",
    "time_table_insert = (\"\"\"\n",
    "    INSERT INTO time (start_time, hour, day, week, month, year, weekday)\n",
    "    SELECT\n",
    "        DISTINCT songplays.start_time       AS start_time,\n",
    "        EXTRACT(HOUR FROM start_time)       AS hour,\n",
    "        EXTRACT(DAY FROM start_time)        AS day,\n",
    "        EXTRACT(WEEK FROM start_time)       AS week,\n",
    "        EXTRACT(MONTH FROM start_time)      AS month,\n",
    "        EXTRACT(YEAR FROM start_time)       AS year,\n",
    "        EXTRACT(weekday FROM start_time)    AS weekday\n",
    "    FROM songplays;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_table = [songplay_table_insert, user_table_insert, song_table_insert, artist_table_insert, time_table_insert]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')\n",
    "\n",
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(songplay_table_insert)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT * FROM songplays\n",
    "    LIMIT 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(964, datetime.datetime(2018, 11, 11, 19, 56, 23), 80, 'paid', '1', 'AR03P141187B9B8CE6', 435, 'Portland-South Portland, ME', '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"')\n",
      "(456, datetime.datetime(2018, 11, 15, 6, 17, 59), 80, 'paid', '1', 'AR049S81187B9AE8A5', 602, 'Portland-South Portland, ME', '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"')\n",
      "(472, datetime.datetime(2018, 11, 6, 16, 32, 54), 30, 'paid', '1', 'AR049S81187B9AE8A5', 130, 'San Jose-Sunnyvale-Santa Clara, CA', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0')\n",
      "(54, datetime.datetime(2018, 11, 26, 13, 21, 9), 88, 'paid', '1', 'AR0DYTO1187FB4B6AE', 900, 'Sacramento--Roseville--Arden-Arcade, CA', '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"')\n",
      "(62, datetime.datetime(2018, 11, 16, 12, 37, 58), 80, 'paid', '1', 'AR0DYTO1187FB4B6AE', 620, 'Portland-South Portland, ME', '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"')\n",
      "(522, datetime.datetime(2018, 11, 24, 18, 10, 25), 80, 'paid', '1', 'AR0HQE41187B9A28D3', 910, 'Portland-South Portland, ME', '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"')\n",
      "(530, datetime.datetime(2018, 11, 28, 18, 39, 10), 88, 'paid', '1', 'AR0HQE41187B9A28D3', 999, 'Sacramento--Roseville--Arden-Arcade, CA', '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"')\n",
      "(17, datetime.datetime(2018, 11, 29, 21, 0, 3), 80, 'paid', '1', 'AR0L04E1187B9AE90C', 1065, 'Portland-South Portland, ME', '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"')\n",
      "(114, datetime.datetime(2018, 11, 27, 22, 3, 51), 80, 'paid', '1', 'AR0Q7DR1187B9AC35D', 992, 'Portland-South Portland, ME', '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"')\n",
      "(880, datetime.datetime(2018, 11, 15, 14, 2, 49), 30, 'paid', '1', 'AR0Y7ET1187FB5763C', 324, 'San Jose-Sunnyvale-Santa Clara, CA', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0')\n"
     ]
    }
   ],
   "source": [
    "row = cur.fetchone()\n",
    "while row:\n",
    "    print(row)\n",
    "    row = cur.fetchone()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
